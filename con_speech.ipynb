{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Political Speech Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Valentin Kassarnig <br>\n",
    "Email: valentin.kassarnig@gmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[constructing dataset...]\n",
      "0\n",
      "[dataset constructed.]\n",
      "tokens 24967\n",
      "speeches 2799\n"
     ]
    }
   ],
   "source": [
    "import con_util\n",
    "reload(con_util)\n",
    "from con_util import *\n",
    "import os\n",
    "\n",
    "# Dataset from http://www.cs.cornell.edu/home/llee/data/convote.html\n",
    "#PATH_TO_DATA = '/Users/hsajjad/Desktop/ted_data_conspeesh_formatted/'\n",
    "PATH_TO_DATA = 'convote_v1.1/data_stage_three'\n",
    "TRAIN_DIR = os.path.join(PATH_TO_DATA, \"training_set\")\n",
    "#TEST_DIR = os.path.join(PATH_TO_DATA, \"test_set\")\n",
    "#DEV_DIR = os.path.join(PATH_TO_DATA, \"development_set\")\n",
    "\n",
    "rank = get_relevant_docs('immigration', \"/Users/hsajjad/Work/software/scripts/document_similarity/trainedModel-conspeech\") # get a ranked list of relevant documents given a keyword\n",
    "\n",
    "positive = rank[0:50] # take 50 best as positive\n",
    "negative = rank[50:]\n",
    "\n",
    "positive = ([t for t,_ in positive])\n",
    "negative = ([t for t,_ in negative])\n",
    "\n",
    "\n",
    "(dataset,vocab) = construct_dataset([TRAIN_DIR,TEST_DIR,DEV_DIR], positive, negative)\n",
    "\n",
    "print \"tokens\",len(vocab)\n",
    "print \"speeches\",sum([len(x) for x in dataset.values()])\n",
    "\n",
    "class_words = get_class_words(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2690"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hsajjad/anaconda/envs/ipykernel_py2/bin/python\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "print sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DN\n",
      "0 / 2750 ...\n",
      "100 / 2750 ...\n",
      "200 / 2750 ...\n",
      "300 / 2750 ...\n",
      "400 / 2750 ...\n",
      "500 / 2750 ...\n",
      "600 / 2750 ...\n",
      "700 / 2750 ...\n",
      "800 / 2750 ...\n",
      "900 / 2750 ...\n",
      "1000 / 2750 ...\n",
      "1100 / 2750 ...\n",
      "1200 / 2750 ...\n",
      "1300 / 2750 ...\n",
      "1400 / 2750 ...\n",
      "1500 / 2750 ...\n",
      "1600 / 2750 ...\n",
      "1700 / 2750 ...\n",
      "1800 / 2750 ...\n",
      "1900 / 2750 ...\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "jk = jk_pos_tag_filter(dataset)\n",
    "pickle.dump( jk, open( \"jk_two_class.p\", \"wb\" ) )\n",
    "jk = pickle.load( open( \"jk_two_class.p\", \"rb\" ) )\n",
    "\n",
    "jk_trend = get_jk_trend(jk,print_n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_probs = get_n_gram_probs(dataset,n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only first time\n",
    "create_corpus_pos_tags(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import con_util\n",
    "reload(con_util)\n",
    "from con_util import *\n",
    "\n",
    "lambd = 0.25\n",
    "speech_class = 'DY'\n",
    "\n",
    "gen_sp =  generate_speech_wba(dataset,ngram_probs,None,None,jk_trend,jk,speech_class,lamb=lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print evaluate_grammar(gen_sp,verbose=False)\n",
    "print evaluate_content(gen_sp,dataset,speech_class,jk,jk_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
